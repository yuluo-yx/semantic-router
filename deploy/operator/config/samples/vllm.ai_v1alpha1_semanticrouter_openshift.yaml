---
apiVersion: vllm.ai/v1alpha1
kind: SemanticRouter
metadata:
  name: semantic-router-openshift
  namespace: vllm-serving
spec:
  # ====================
  # Image Configuration
  # ====================
  image:
    repository: ghcr.io/vllm-project/semantic-router/extproc
    tag: latest
    pullPolicy: IfNotPresent
    # imageRegistry: quay.io  # Optional registry prefix

  # ====================
  # Deployment Settings
  # ====================
  replicas: 2

  # imagePullSecrets:
  #   - name: my-registry-secret

  # ====================
  # NEW: vLLM Backend Endpoints Configuration
  # ====================
  # Configure model backends that semantic router routes to after classification
  # Generates vllm_endpoints and model_config sections in ConfigMap
  vllmEndpoints:
    # Example 1: KServe InferenceService (RHOAI 3)
    - name: kserve-llama3-8b
      model: llama3-8b
      reasoningFamily: qwen3
      backend:
        type: kserve
        inferenceServiceName: llama-3-8b  # InferenceService in same namespace
      weight: 1  # Load balancing weight

    # Example 2: KServe InferenceService with reasoning disabled
    - name: kserve-qwen-2-5-7b
      model: qwen2.5-7b
      reasoningFamily: qwen3
      backend:
        type: kserve
        inferenceServiceName: qwen-2-5-7b

    # Example 3: Llama Stack service discovery
    - name: llamastack-llama-405b
      model: llama-3.3-70b-instruct
      reasoningFamily: gpt
      backend:
        type: llamastack
        discoveryLabels:
          app: llama-stack
          model: llama-3.3-70b

    # Example 4: Direct Kubernetes service
    - name: vllm-custom-model
      model: deepseek-r1-distill-qwen-7b
      reasoningFamily: deepseek
      backend:
        type: service
        service:
          name: vllm-deepseek
          namespace: vllm-serving  # Can reference service in another namespace
          port: 8000

  # ====================
  # NEW: Gateway Integration (Optional)
  # ====================
  # Reuse existing Gateway (Envoy Gateway, Istio) instead of deploying Envoy sidecar
  # When configured, operator creates HTTPRoute and skips Envoy sidecar container
  gateway:
    existingRef:
      name: istio-ingressgateway
      namespace: istio-system

  # ====================
  # NEW: OpenShift Routes (Optional)
  # ====================
  # Create OpenShift Route for external access
  openshift:
    routes:
      enabled: true
      hostname: semantic-router.apps.openshift.example.com  # Optional - auto-generated if omitted
      tls:
        termination: edge  # edge, passthrough, or reencrypt
        insecureEdgeTerminationPolicy: Redirect  # Redirect HTTP to HTTPS

  # ====================
  # Service Configuration
  # ====================
  service:
    type: ClusterIP
    grpc:
      port: 50051
      targetPort: 50051
    api:
      port: 8080
      targetPort: 8080
    metrics:
      enabled: true
      port: 9190
      targetPort: 9190

  # ====================
  # Persistence Configuration (NEW: Validated Storage)
  # ====================
  persistence:
    enabled: true
    # If storageClassName not specified, uses cluster default StorageClass
    # Operator validates StorageClass exists before creating PVC
    storageClassName: gp3  # AWS EBS, adjust for your cluster
    size: 20Gi
    accessMode: ReadWriteOnce
    # existingClaim: my-existing-pvc  # Use existing PVC instead

  # ====================
  # Resource Requirements
  # ====================
  resources:
    requests:
      cpu: 2000m
      memory: 4Gi
    limits:
      cpu: 4000m
      memory: 8Gi

  # ====================
  # Semantic Router Configuration
  # ====================
  config:
    # BERT model for embeddings
    bert_model:
      model_id: models/mom-embedding-light
      threshold: "0.6"
      use_cpu: true

    # Semantic cache for latency/token optimization
    semantic_cache:
      enabled: true
      backend_type: memory  # or milvus
      similarity_threshold: "0.85"  # Higher = more strict matching
      max_entries: 10000
      ttl_seconds: 3600  # 1 hour
      eviction_policy: lru  # fifo, lru, or lfu

    # Tools auto-selection based on semantic similarity
    tools:
      enabled: true
      top_k: 3
      similarity_threshold: "0.2"
      tools_db_path: config/tools_db.json
      fallback_to_empty: true

    # Prompt guard (jailbreak detection)
    prompt_guard:
      enabled: true
      use_modernbert: false
      model_id: models/mom-jailbreak-classifier
      threshold: "0.7"
      use_cpu: true

    # Category and PII classifiers
    classifier:
      category_model:
        model_id: models/mom-category-classifier
        use_modernbert: false
        threshold: "0.5"
        use_cpu: true
      pii_model:
        model_id: models/mom-pii-classifier
        use_modernbert: false
        threshold: "0.7"
        use_cpu: true

    # Reasoning families configuration
    reasoning_families:
      qwen3:
        type: chat_template_kwargs
        parameter: enable_thinking
      deepseek:
        type: chat_template_kwargs
        parameter: thinking
      gpt:
        type: reasoning_effort
        parameter: reasoning_effort

    default_reasoning_effort: medium  # low, medium, high

    # API configuration
    api:
      batch_classification:
        max_batch_size: 100
        concurrency_threshold: 5
        max_concurrency: 8
        metrics:
          enabled: true
          detailed_goroutine_tracking: true
          high_resolution_timing: false
          sample_rate: "1.0"

    # Observability (OpenTelemetry tracing)
    observability:
      tracing:
        enabled: true
        provider: opentelemetry
        exporter:
          type: otlp
          endpoint: jaeger-collector.observability.svc.cluster.local:4317
          insecure: true
        sampling:
          type: probabilistic
          probability: "0.1"  # Sample 10% of traces
        resource:
          service_name: semantic-router
          environment: production

  # ====================
  # Tools Database
  # ====================
  # Define tools for auto-selection based on query similarity
  toolsDb:
    - name: get_weather
      description: Get the current weather for a location
      parameters:
        type: object
        properties:
          location:
            type: string
            description: City name or coordinates
          unit:
            type: string
            enum: [celsius, fahrenheit]
        required: [location]

    - name: search_knowledge_base
      description: Search internal knowledge base for company information
      parameters:
        type: object
        properties:
          query:
            type: string
            description: Search query
          max_results:
            type: integer
            description: Maximum number of results
            default: 5
        required: [query]

    - name: calculate
      description: Perform mathematical calculations
      parameters:
        type: object
        properties:
          expression:
            type: string
            description: Mathematical expression to evaluate
        required: [expression]

  # ====================
  # Autoscaling (HPA)
  # ====================
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70
    targetMemoryUtilizationPercentage: 80

  # ====================
  # Health Probes
  # ====================
  startupProbe:
    httpGet:
      path: /health
      port: 8080
    initialDelaySeconds: 10
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 30

  livenessProbe:
    httpGet:
      path: /health
      port: 8080
    periodSeconds: 10
    timeoutSeconds: 3
    failureThreshold: 3

  readinessProbe:
    httpGet:
      path: /ready
      port: 8080
    periodSeconds: 5
    timeoutSeconds: 3
    failureThreshold: 3

  # ====================
  # Security Context (OpenShift SCC compliant)
  # ====================
  securityContext:
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - ALL
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault

  podSecurityContext:
    runAsNonRoot: true
    seccompProfile:
      type: RuntimeDefault

  # ====================
  # Scheduling Configuration
  # ====================
  nodeSelector:
    node-role.kubernetes.io/worker: ""
    # Example: GPU nodes
    # accelerator: gpu

  tolerations:
    - key: "node.kubernetes.io/not-ready"
      operator: "Exists"
      effect: "NoExecute"
      tolerationSeconds: 300
    # Example: GPU taints
    # - key: "nvidia.com/gpu"
    #   operator: "Exists"
    #   effect: "NoSchedule"

  affinity:
    podAntiAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          podAffinityTerm:
            labelSelector:
              matchExpressions:
                - key: app.kubernetes.io/name
                  operator: In
                  values:
                    - semantic-router
            topologyKey: kubernetes.io/hostname

  # ====================
  # Pod Annotations
  # ====================
  podAnnotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "9190"
    prometheus.io/path: "/metrics"

  # ====================
  # Environment Variables
  # ====================
  env:
    - name: RUST_LOG
      value: info
    - name: RUST_BACKTRACE
      value: "1"
    # Example: External service credentials
    # - name: API_KEY
    #   valueFrom:
    #     secretKeyRef:
    #       name: api-credentials
    #       key: api-key

  # ====================
  # Service Account
  # ====================
  serviceAccount:
    create: true
    name: semantic-router
    annotations:
      # Example: AWS IAM role for service account
      # eks.amazonaws.com/role-arn: arn:aws:iam::123456789012:role/semantic-router-role
