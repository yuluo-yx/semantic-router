apiVersion: vllm.ai/v1alpha1
kind: SemanticRouter
metadata:
  name: semanticrouter-sample
  namespace: default
spec:
  # Number of replicas
  replicas: 1

  # Image configuration
  image:
    repository: ghcr.io/vllm-project/semantic-router/extproc
    tag: latest
    pullPolicy: IfNotPresent

  # Service configuration
  service:
    type: ClusterIP
    grpc:
      port: 50051
      targetPort: 50051
    api:
      port: 8080
      targetPort: 8080
    metrics:
      enabled: true
      port: 9190
      targetPort: 9190

  # Resource requirements
  resources:
    limits:
      memory: "7Gi"
      cpu: "2"
    requests:
      memory: "3Gi"
      cpu: "1"

  # Persistence configuration
  persistence:
    enabled: true
    storageClassName: "standard"
    accessMode: ReadWriteOnce
    size: 10Gi

  # Startup probe configuration (for model loading)
  startupProbe:
    enabled: true
    periodSeconds: 10
    timeoutSeconds: 5
    failureThreshold: 360  # 60 minutes total timeout

  # Liveness probe
  livenessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 5

  # Readiness probe
  readinessProbe:
    enabled: true
    initialDelaySeconds: 30
    periodSeconds: 30
    timeoutSeconds: 10
    failureThreshold: 5

  # Security context (optional - will be set automatically based on platform)
  # On OpenShift: SecurityContext is automatically configured to work with SCCs
  # On Kubernetes: Defaults to runAsUser: 1000, runAsNonRoot: true, allowPrivilegeEscalation: false
  # Uncomment to override:
  # securityContext:
  #   runAsNonRoot: true
  #   runAsUser: 1000
  #   allowPrivilegeEscalation: false
  #   capabilities:
  #     drop:
  #       - ALL

  # Pod security context (optional - will be set automatically based on platform)
  # On OpenShift: No runAsUser/fsGroup set (SCC assigns them)
  # On Kubernetes: Defaults to runAsUser: 1000, fsGroup: 1000, runAsNonRoot: true
  # Uncomment to override:
  # podSecurityContext:
  #   runAsNonRoot: true
  #   runAsUser: 1000
  #   fsGroup: 1000

  # Environment variables
  env:
    - name: LD_LIBRARY_PATH
      value: "/app/lib"
    - name: HF_TOKEN
      valueFrom:
        secretKeyRef:
          name: hf-token-secret
          key: token
          optional: true

  # Container arguments
  args:
    - "--secure=false"

  # vLLM Backend Endpoints - Configure model backends to route to
  vllmEndpoints:
    # Example: KServe InferenceService backend
    - name: llama3-8b-endpoint
      model: llama3-8b
      reasoningFamily: qwen3
      backend:
        type: kserve
        inferenceServiceName: llama-3-8b
      weight: 1

    # Example: Direct service backend
    - name: qwen-endpoint
      model: qwen2.5-7b
      reasoningFamily: qwen3
      backend:
        type: service
        service:
          name: vllm-qwen
          namespace: default
          port: 8000
      weight: 1

  # Semantic Router configuration
  config:
    # BERT model for embeddings
    bert_model:
      model_id: "models/mom-embedding-light"
      threshold: "0.6"
      use_cpu: true

    # Semantic cache for response caching
    semantic_cache:
      enabled: true
      backend_type: "memory"
      similarity_threshold: "0.8"
      max_entries: 1000
      ttl_seconds: 3600
      eviction_policy: "fifo"

    # Tools auto-selection
    tools:
      enabled: true
      top_k: 3
      similarity_threshold: "0.2"
      tools_db_path: "config/tools_db.json"
      fallback_to_empty: true

    # Prompt guard / jailbreak detection
    prompt_guard:
      enabled: true
      use_modernbert: false
      model_id: "models/mom-jailbreak-classifier"
      threshold: "0.7"
      use_cpu: true
      jailbreak_mapping_path: "models/mom-jailbreak-classifier/jailbreak_type_mapping.json"

    # Classifiers for category and PII detection
    classifier:
      category_model:
        model_id: "models/lora_intent_classifier_bert-base-uncased_model"
        use_modernbert: false
        threshold: "0.6"
        use_cpu: true
        category_mapping_path: "models/lora_intent_classifier_bert-base-uncased_model/category_mapping.json"
      pii_model:
        model_id: "models/mom-pii-classifier"
        use_modernbert: true
        threshold: "0.7"
        use_cpu: true
        pii_mapping_path: "models/mom-pii-classifier/pii_type_mapping.json"

    # Reasoning mode configuration per model family
    reasoning_families:
      deepseek:
        type: "chat_template_kwargs"
        parameter: "thinking"
      qwen3:
        type: "chat_template_kwargs"
        parameter: "enable_thinking"
      gpt-oss:
        type: "reasoning_effort"
        parameter: "reasoning_effort"
      gpt:
        type: "reasoning_effort"
        parameter: "reasoning_effort"

    # Default reasoning effort level
    default_reasoning_effort: high

    # API configuration
    api:
      batch_classification:
        max_batch_size: 100
        concurrency_threshold: 5
        max_concurrency: 8
        metrics:
          enabled: true
          detailed_goroutine_tracking: true
          high_resolution_timing: false
          sample_rate: "1.0"
          duration_buckets: ["0.001", "0.005", "0.01", "0.025", "0.05", "0.1", "0.25", "0.5", "1", "2.5", "5", "10", "30"]
          size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]

    # Observability / tracing configuration
    observability:
      tracing:
        enabled: false
        provider: "opentelemetry"
        exporter:
          type: "otlp"
          endpoint: "jaeger:4317"
          insecure: true
        sampling:
          type: "always_on"
          rate: "1.0"
        resource:
          service_name: "vllm-semantic-router"
          service_version: "v0.1.0"
          deployment_environment: "development"

  # Tools database - define available tools for auto-selection
  toolsDb:
    - tool:
        type: "function"
        function:
          name: "get_weather"
          description: "Get current weather information for a location"
          parameters:
            type: "object"
            properties:
              location:
                type: "string"
                description: "The city and state, e.g. San Francisco, CA"
              unit:
                type: "string"
                enum: ["celsius", "fahrenheit"]
                description: "Temperature unit"
            required: ["location"]
      description: "Get current weather information, temperature, conditions, forecast for any location"
      category: "weather"
      tags: ["weather", "temperature", "forecast", "climate"]
    - tool:
        type: "function"
        function:
          name: "search_web"
          description: "Search the web for information"
          parameters:
            type: "object"
            properties:
              query:
                type: "string"
                description: "The search query"
              num_results:
                type: "integer"
                description: "Number of results to return"
                default: 5
            required: ["query"]
      description: "Search the internet, web search, find information online"
      category: "search"
      tags: ["search", "web", "internet", "information", "browse"]
    - tool:
        type: "function"
        function:
          name: "calculate"
          description: "Perform mathematical calculations"
          parameters:
            type: "object"
            properties:
              expression:
                type: "string"
                description: "Mathematical expression to evaluate"
            required: ["expression"]
      description: "Calculate mathematical expressions, solve math problems"
      category: "math"
      tags: ["math", "calculation", "arithmetic", "compute", "numbers"]

  # Autoscaling (optional)
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilizationPercentage: 80

  # Ingress (optional)
  ingress:
    enabled: false
    className: ""
    annotations: {}
    hosts:
      - host: semantic-router.local
        paths:
          - path: /
            pathType: Prefix
            servicePort: 8080
