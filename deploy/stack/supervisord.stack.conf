; Supervisord Configuration for vLLM Semantic Router Stack

[supervisord]
nodaemon=true
logfile=/var/log/supervisor/supervisord.log
pidfile=/var/run/supervisor/supervisord.pid
childlogdir=/var/log/supervisor
loglevel=info
user=root

[unix_http_server]
file=/var/run/supervisor/supervisor.sock
chmod=0700

[supervisorctl]
serverurl=unix:///var/run/supervisor/supervisor.sock

[rpcinterface:supervisor]
supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface

; Services (ordered by priority)

; Priority 3: MongoDB must start first (chat-ui database)
[program:mongodb]
command=/usr/local/bin/mongod --dbpath=%(ENV_MONGODB_DATA_PATH)s --bind_ip=127.0.0.1 --port=27017 --logpath=/var/log/supervisor/mongodb.log --logappend
autostart=true
autorestart=true
priority=3
startsecs=5
stopwaitsecs=15
stdout_logfile=/dev/null
stdout_logfile_maxbytes=0
stderr_logfile=/var/log/supervisor/mongodb-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=2

; Priority 5: Jaeger must start first (tracing backend)
[program:jaeger]
command=/usr/local/bin/jaeger-all-in-one
environment=COLLECTOR_OTLP_ENABLED="true"
autostart=true
autorestart=true
priority=5
startsecs=5
stopwaitsecs=10
stdout_logfile=/var/log/supervisor/jaeger.log
stdout_logfile_maxbytes=20MB
stdout_logfile_backups=2
stderr_logfile=/var/log/supervisor/jaeger-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=2

; Priority 7: LLM-Katan (lightweight LLM server, must start before semantic-router tests upstream)
[program:llmkatan]
command=/opt/llmkatan-env/bin/llm-katan --model %(ENV_LLMKATAN_MODEL)s --served-model-name %(ENV_LLMKATAN_SERVED_MODEL_NAME)s --host 127.0.0.1 --port %(ENV_LLMKATAN_PORT)s
directory=/app
environment=PYTHONUNBUFFERED="1",HF_HOME="/app/models",TRANSFORMERS_CACHE="/app/models"
autostart=true
autorestart=true
priority=7
startsecs=30
stopwaitsecs=15
stdout_logfile=/var/log/supervisor/llmkatan.log
stdout_logfile_maxbytes=20MB
stdout_logfile_backups=2
stderr_logfile=/var/log/supervisor/llmkatan-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=2

; Priority 10: semantic-router (Envoy depends on it)
[program:semantic-router]
command=/app/extproc-server
environment=LD_LIBRARY_PATH="/app/lib",CONFIG_FILE="%(ENV_CONFIG_FILE)s"
directory=/app
autostart=true
autorestart=true
priority=10
startsecs=10
stopwaitsecs=30
stdout_logfile=/var/log/supervisor/semantic-router.log
stdout_logfile_maxbytes=50MB
stdout_logfile_backups=3
stderr_logfile=/var/log/supervisor/semantic-router-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=3

; Priority 15: Prometheus (metrics collection)
[program:prometheus]
command=/usr/local/bin/prometheus --config.file=/etc/prometheus/prometheus.yml --storage.tsdb.path=/var/lib/prometheus --storage.tsdb.retention.time=15d --web.listen-address=:9090
autostart=true
autorestart=true
priority=15
startsecs=5
stopwaitsecs=10
stdout_logfile=/var/log/supervisor/prometheus.log
stdout_logfile_maxbytes=20MB
stdout_logfile_backups=2
stderr_logfile=/var/log/supervisor/prometheus-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=2

; Priority 20: Envoy (starts after semantic-router)
[program:envoy]
command=/usr/local/bin/envoy -c /etc/envoy/envoy.yaml --component-log-level ext_proc:info,router:info
autostart=true
autorestart=true
priority=20
startsecs=5
stopwaitsecs=30
stdout_logfile=/var/log/supervisor/envoy.log
stdout_logfile_maxbytes=50MB
stdout_logfile_backups=3
stderr_logfile=/var/log/supervisor/envoy-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=3

; Priority 25: Grafana (depends on Prometheus)
[program:grafana]
command=/opt/grafana/bin/grafana server --homepath=/opt/grafana --config=/opt/grafana/conf/defaults.ini
environment=GF_PATHS_DATA="/var/lib/grafana",GF_PATHS_PROVISIONING="/etc/grafana/provisioning",GF_SECURITY_ADMIN_USER="%(ENV_GF_SECURITY_ADMIN_USER)s",GF_SECURITY_ADMIN_PASSWORD="%(ENV_GF_SECURITY_ADMIN_PASSWORD)s",GF_SERVER_HTTP_PORT="3000",GF_SECURITY_ALLOW_EMBEDDING="true",GF_AUTH_ANONYMOUS_ENABLED="true",GF_AUTH_ANONYMOUS_ORG_ROLE="Viewer"
autostart=true
autorestart=true
priority=25
startsecs=10
stopwaitsecs=10
stdout_logfile=/var/log/supervisor/grafana.log
stdout_logfile_maxbytes=20MB
stdout_logfile_backups=2
stderr_logfile=/var/log/supervisor/grafana-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=2

; Priority 30: Dashboard (can start in parallel)
[program:dashboard]
command=/app/dashboard-backend -port=%(ENV_DASHBOARD_PORT)s -static=/app/frontend -config=%(ENV_CONFIG_FILE)s
directory=/app
autostart=true
autorestart=true
priority=30
startsecs=5
stopwaitsecs=10
stdout_logfile=/var/log/supervisor/dashboard.log
stdout_logfile_maxbytes=20MB
stdout_logfile_backups=2
stderr_logfile=/var/log/supervisor/dashboard-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=2

; Priority 50: chat-ui (HuggingChat - depends on MongoDB and Envoy)
; Start later to ensure backend is ready
[program:chatui]
command=node /app/chatui/build
directory=/app/chatui
environment=MONGODB_URL="%(ENV_MONGODB_URL)s",MONGODB_DB_NAME="%(ENV_MONGODB_DB_NAME)s",OPENAI_BASE_URL="%(ENV_OPENAI_BASE_URL)s",OPENAI_API_KEY="%(ENV_OPENAI_API_KEY)s",PORT="%(ENV_CHATUI_PORT)s",PUBLIC_APP_NAME="%(ENV_PUBLIC_APP_NAME)s",PUBLIC_APP_ASSETS="%(ENV_PUBLIC_APP_ASSETS)s",COOKIE_SECURE="%(ENV_COOKIE_SECURE)s",COOKIE_NAME="%(ENV_COOKIE_NAME)s",COOKIE_SAMESITE="%(ENV_COOKIE_SAMESITE)s",APP_BASE_URL="%(ENV_APP_BASE_URL)s"
autostart=true
autorestart=true
priority=50
startsecs=15
stopwaitsecs=10
stdout_logfile=/var/log/supervisor/chatui.log
stdout_logfile_maxbytes=20MB
stdout_logfile_backups=2
stderr_logfile=/var/log/supervisor/chatui-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=2

; Priority 33: Pipelines (runs independently with its own Python env)
[program:pipelines]
command=/opt/pipelines-env/bin/python -m uvicorn main:app --host 0.0.0.0 --port %(ENV_PIPELINES_PORT)s
directory=/app/pipelines
environment=PYTHONUNBUFFERED="1",PYTHONPATH="/app/pipelines",LD_LIBRARY_PATH="/opt/pipelines-env/lib",PIPELINES_DIR="/app/pipelines"
autostart=true
autorestart=true
priority=33
startsecs=10
stopwaitsecs=10
stdout_logfile=/var/log/supervisor/pipelines.log
stdout_logfile_maxbytes=20MB
stdout_logfile_backups=2
stderr_logfile=/var/log/supervisor/pipelines-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=2

; Priority 55: Open WebUI (depends on Pipelines, uses its own Python env)
; Start later to ensure Pipelines backend is ready
[program:openwebui]
command=/opt/openwebui-env/bin/python -m uvicorn open_webui.main:app --host 0.0.0.0 --port %(ENV_OPENWEBUI_PORT)s --forwarded-allow-ips '*'
directory=/app/openwebui/backend
environment=OPENAI_API_BASE_URL="http://localhost:%(ENV_PIPELINES_PORT)s",OPENAI_API_KEY="0p3n-w3bu!",DATA_DIR="%(ENV_OPENWEBUI_DATA_DIR)s",WEBUI_NAME="Open WebUI",PYTHONPATH="/app/openwebui/backend",LD_LIBRARY_PATH="/opt/openwebui-env/lib"
autostart=true
autorestart=true
priority=55
startsecs=15
stopwaitsecs=10
stdout_logfile=/var/log/supervisor/openwebui.log
stdout_logfile_maxbytes=20MB
stdout_logfile_backups=2
stderr_logfile=/var/log/supervisor/openwebui-error.log
stderr_logfile_maxbytes=10MB
stderr_logfile_backups=2

; Service Groups
[group:core]
programs=semantic-router,envoy,dashboard,chatui,openwebui,pipelines,llmkatan
priority=100

[group:observability]
programs=prometheus,grafana,jaeger

[group:database]
programs=mongodb
priority=50
