# Configuration for hallucination detection benchmark
# Connects to real vLLM server at port 8083

bert_model:
  model_id: models/mom-embedding-light
  threshold: 0.6
  use_cpu: true

semantic_cache:
  enabled: false  # Disable cache for benchmarking

# Classifier configuration
classifier:
  category_model:
    model_id: "models/mom-domain-classifier"
    use_modernbert: true
    threshold: 0.6
    use_cpu: true
    category_mapping_path: "models/mom-domain-classifier/category_mapping.json"
  pii_model:
    model_id: "models/pii_classifier_modernbert-base_presidio_token_model"
    use_modernbert: true
    threshold: 0.7
    use_cpu: true
    pii_mapping_path: "models/mom-pii-classifier/pii_type_mapping.json"

# Hallucination mitigation configuration
hallucination_mitigation:
  enabled: true

  # Fact-check classifier: determines if a prompt needs fact verification
  fact_check_model:
    model_id: "models/mom-halugate-sentinel"
    threshold: 0.6
    use_cpu: true

  # Hallucination detector: verifies if LLM response is grounded in context
  # Using base model (149M params) for balanced accuracy and speed
  hallucination_model:
    model_id: "models/mom-halugate-detector"
    threshold: 0.5
    use_cpu: true
    # False positive reduction settings
    min_span_length: 1  # Minimum tokens in a span to report
    min_span_confidence: 0.3  # Minimum confidence for a span
    context_window_size: 50  # Context around spans (chars)
    enable_nli_filtering: true  # Filter false positives with NLI
    nli_entailment_threshold: 0.50  # High entailment = likely false positive

  # NLI model: provides explanations for hallucinated spans
  nli_model:
    model_id: "models/mom-halugate-explainer"
    threshold: 0.7
    use_cpu: true

  # Action when hallucination detected: "warn" adds headers, "block" returns error
  on_hallucination_detected: "warn"

# Fact-check rules for signal classification
# The classifier outputs one of these signals that can be referenced in decision conditions
fact_check_rules:
  - name: needs_fact_check
    description: "Query contains factual claims that should be verified against context"
  - name: no_fact_check_needed
    description: "Query is creative, code-related, or opinion-based - no fact verification needed"

# Prompt guard
prompt_guard:
  enabled: true
  use_modernbert: true
  model_id: "models/mom-jailbreak-classifier"
  threshold: 0.7
  use_cpu: true
  jailbreak_mapping_path: "models/mom-jailbreak-classifier/jailbreak_type_mapping.json"

# vLLM endpoint - real vLLM server
vllm_endpoints:
  - name: "vllm-general"
    address: "127.0.0.1"
    port: 8083
    weight: 1
    health_check_path: "/health"

# Model configuration - use the actual model from vLLM
model_config:
  "Qwen/Qwen2.5-14B-Instruct-AWQ":
    reasoning_family: "qwen3"
    preferred_endpoints: ["vllm-general"]

# Categories for routing
categories:
  - name: general
    description: "General questions"
    mmlu_categories: ["other"]
  - name: math
    description: "Mathematics and quantitative reasoning"
    mmlu_categories: ["math"]
  - name: science
    description: "Science questions"
    mmlu_categories: ["physics", "chemistry", "biology"]

strategy: "priority"

decisions:
  - name: "math_decision"
    description: "Mathematics and quantitative reasoning"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "math"
    modelRefs:
      - model: "Qwen/Qwen2.5-14B-Instruct-AWQ"
        use_reasoning: true
    plugins:
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []
      - type: "hallucination"
        configuration:
          enabled: true
          use_nli: true
          hallucination_action: "header"
          unverified_factual_action: "header"
          include_hallucination_details: false

  - name: "science_decision"
    description: "Science questions"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "science"
    modelRefs:
      - model: "Qwen/Qwen2.5-14B-Instruct-AWQ"
        use_reasoning: true
    plugins:
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []
      - type: "hallucination"
        configuration:
          enabled: true
          use_nli: true
          hallucination_action: "header"
          unverified_factual_action: "header"
          include_hallucination_details: false

  - name: "general_decision"
    description: "General questions"
    priority: 50
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "general"
    modelRefs:
      - model: "Qwen/Qwen2.5-14B-Instruct-AWQ"
        use_reasoning: false
    plugins:
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []
      - type: "hallucination"
        configuration:
          enabled: true
          use_nli: true
          hallucination_action: "header"
          unverified_factual_action: "header"
          include_hallucination_details: false

default_model: "Qwen/Qwen2.5-14B-Instruct-AWQ"

# API Configuration
api:
  batch_classification:
    metrics:
      enabled: true
      detailed_goroutine_tracking: true
      high_resolution_timing: false
      sample_rate: 1.0

