bert_model:
  model_id: models/all-MiniLM-L12-v2
  threshold: 0.6
  use_cpu: true

semantic_cache:
  enabled: true
  backend_type: "hybrid"  # Hybrid HNSW + Milvus backend
  similarity_threshold: 0.85
  ttl_seconds: 3600

  # Hybrid cache specific settings
  max_memory_entries: 100000  # Max entries in HNSW index (100K)

  # HNSW parameters
  hnsw_m: 16  # Number of bi-directional links
  hnsw_ef_construction: 200  # Construction quality parameter

  # Milvus configuration file path
  backend_config_path: "config/semantic-cache/milvus.yaml"

tools:
  enabled: true
  top_k: 3
  similarity_threshold: 0.2
  tools_db_path: "config/tools_db.json"
  fallback_to_empty: true

prompt_guard:
  enabled: true
  use_modernbert: true
  model_id: "models/jailbreak_classifier_modernbert-base_model"
  threshold: 0.7
  use_cpu: true
  jailbreak_mapping_path: "models/jailbreak_classifier_modernbert-base_model/jailbreak_type_mapping.json"

# vLLM Endpoints Configuration
vllm_endpoints:
  - name: "endpoint1"
    address: "172.28.0.20"
    port: 8002
    weight: 1

model_config:
  "qwen3":
    reasoning_family: "qwen3"
    preferred_endpoints: ["endpoint1"]
    pii_policy:
      allow_by_default: true

# Classifier configuration
classifier:
  enabled: true
  model_path: "models/qwen3-router_model/router_qwen_generative_model.safetensors"
  tokenizer_path: "models/qwen3-router_model"
  use_cpu: true
  threshold: 0.7

