# You can override by specifying your own mappings below:
# Uncomment and customize if you need different model mappings:
# mom_registry:
#   "models/mom-domain-classifier": "LLM-Semantic-Router/lora_intent_classifier_bert-base-uncased_model"
#   "models/mom-pii-classifier": "LLM-Semantic-Router/lora_pii_detector_bert-base-uncased_model"
#   "models/mom-jailbreak-classifier": "LLM-Semantic-Router/lora_jailbreak_classifier_bert-base-uncased_model"
#   "models/mom-halugate-detector": "KRLabsOrg/lettucedect-base-modernbert-en-v1"
#   "models/mom-halugate-sentinel": "LLM-Semantic-Router/halugate-sentinel"
#   "models/mom-halugate-explainer": "tasksource/ModernBERT-base-nli"
#   "models/mom-embedding-pro": "Qwen/Qwen3-Embedding-0.6B"
#   "models/mom-embedding-flash": "google/embeddinggemma-300m"

# Response API Configuration
# Enables OpenAI Response API support with conversation chaining
response_api:
  enabled: true
  store_backend: "memory"  # Options: "memory", "milvus", "redis"
  ttl_seconds: 86400       # 24 hours
  max_responses: 1000

# Router Replay Configuration
# Records routing decisions for debugging and analysis
# Automatically creates isolated storage per decision (collection/table/keyspace)
router_replay:
  enabled: false
  store_backend: "memory"           # Options: "memory", "redis", "postgres", "milvus"
  ttl_seconds: 2592000             # 30 days
  capture_request_body: true
  capture_response_body: true
  max_body_bytes: 4096
  async_writes: true
  # Memory backend settings
  max_records: 1000
  # Redis backend settings (uncomment if using Redis)
  # redis:
  #   address: "redis:6379"
  #   db: 0
  #   key_prefix: "router_replay"
  # PostgreSQL backend settings (uncomment if using PostgreSQL)
  # postgres:
  #   host: "postgres"
  #   port: 5432
  #   database: "semantic_router"
  #   user: "router"
  #   password: "router_password"
  #   table_name: "replay_records"
  # Milvus backend settings (uncomment if using Milvus)
  # milvus:
  #   address: "milvus:19530"
  #   collection_name: "replay_records"

semantic_cache:
  enabled: true
  backend_type: "memory"  # Options: "memory", "milvus", or "hybrid"
  similarity_threshold: 0.8
  max_entries: 1000  # Only applies to memory backend
  ttl_seconds: 3600
  eviction_policy: "fifo"
  # HNSW index configuration (for memory backend only)
  use_hnsw: true  # Enable HNSW index for faster similarity search
  hnsw_m: 16  # Number of bi-directional links (higher = better recall, more memory)
  hnsw_ef_construction: 200  # Construction parameter (higher = better quality, slower build)

  # Hybrid cache configuration (when backend_type: "hybrid")
  # Combines in-memory HNSW for fast search with Milvus for scalable storage
  # max_memory_entries: 100000 # Max entries in HNSW index (default: 100,000)
  # backend_config_path: "config/milvus.yaml" # Path to Milvus config

  # Embedding model for semantic similarity matching
  # Options: "bert" (fast, 384-dim), "qwen3" (high quality, 1024-dim, 32K context), "gemma" (balanced, 768-dim, 8K context)
  # Default: "bert" (fastest, lowest memory)
  embedding_model: "qwen2.5:3b"

tools:
  enabled: true
  top_k: 3
  similarity_threshold: 0.2
  tools_db_path: "config/tools_db.json"
  fallback_to_empty: true
  advanced_filtering:
    enabled: false
    # candidate_pool_size: 20
    # min_lexical_overlap: 1
    # min_combined_score: 0.35
    # weights:
    #   embed: 0.7
    #   lexical: 0.2
    #   tag: 0.05
    #   name: 0.05
    #   category: 0.1
    # use_category_filter: true
    # category_confidence_threshold: 0.6
    # allow_tools: []
    # block_tools: []

prompt_guard:
  enabled: true  # Global default - can be overridden per category with jailbreak_enabled
  use_modernbert: false
  model_id: "models/mom-jailbreak-classifier"
  threshold: 0.7
  use_cpu: true
jailbreak_mapping_path: "models/mom-jailbreak-classifier/label_mapping.json"

# Classifier configuration
classifier:
  category_model:
    model_id: "models/mom-domain-classifier"
    threshold: 0.6
    use_cpu: true
    category_mapping_path: "models/mom-domain-classifier/category_mapping.json"
  pii_model:
    model_id: "models/mom-pii-classifier"
    use_modernbert: false
    threshold: 0.9
    use_cpu: true
  pii_mapping_path: "models/mom-pii-classifier/label_mapping.json"

# Hallucination mitigation configuration
# Disabled by default - enable in decisions via hallucination plugin
hallucination_mitigation:
  enabled: false
  # Fact-check classifier: determines if a prompt needs fact verification
  fact_check_model:
    model_id: "models/mom-halugate-sentinel"
    threshold: 0.6
    use_cpu: true
  # Hallucination detector: verifies if LLM response is grounded in context
  hallucination_model:
    model_id: "models/mom-halugate-detector"
    threshold: 0.8
    use_cpu: true
    # False positive reduction settings
    min_span_length: 2  # Minimum tokens in a span to report (filters single-token false positives)
    min_span_confidence: 0.6  # Minimum confidence for a span to be reported
    context_window_size: 50  # Characters of context around flagged spans
    enable_nli_filtering: true  # Use NLI to filter false positives
    nli_entailment_threshold: 0.75  # Filter spans with high entailment scores
  # NLI model: provides explanations for hallucinated spans
  nli_model:
    model_id: "models/mom-halugate-explainer"
    threshold: 0.9
    use_cpu: true

# vLLM Endpoints Configuration
# The 'address' field can be an IP address (IPv4 or IPv6) or a domain name
# Supported formats: 127.0.0.1, 192.168.1.1, ::1, 2001:db8::1, example.com, localhost
# Note: Use the 'port' field for port numbers, not in the address field
vllm_endpoints:
  - name: "ollama"
    address: "127.0.0.1"  # Ollama endpoint for testing
    port: 11434
    weight: 1

model_config:
  "qwen2.5:3b":
    reasoning_family: "qwen3"  # Qwen2.5 uses similar reasoning syntax to Qwen3
    preferred_endpoints: ["ollama"]

# Categories define domain metadata only (no routing logic)
categories:
  - name: business
    description: "Business and management related queries"
    mmlu_categories: ["business"]
  - name: law
    description: "Legal questions and law-related topics"
    mmlu_categories: ["law"]
  - name: psychology
    description: "Psychology and mental health topics"
    mmlu_categories: ["psychology"]
  - name: biology
    description: "Biology and life sciences questions"
    mmlu_categories: ["biology"]
  - name: chemistry
    description: "Chemistry and chemical sciences questions"
    mmlu_categories: ["chemistry"]
  - name: history
    description: "Historical questions and cultural topics"
    mmlu_categories: ["history"]
  - name: other
    description: "General knowledge and miscellaneous topics"
    mmlu_categories: ["other"]
  - name: health
    description: "Health and medical information queries"
    mmlu_categories: ["health"]
  - name: economics
    description: "Economics and financial topics"
    mmlu_categories: ["economics"]
  - name: math
    description: "Mathematics and quantitative reasoning"
    mmlu_categories: ["math"]
  - name: physics
    description: "Physics and physical sciences"
    mmlu_categories: ["physics"]
  - name: computer_science
    description: "Computer science and programming"
    mmlu_categories: ["computer_science"]
  - name: philosophy
    description: "Philosophy and ethical questions"
    mmlu_categories: ["philosophy"]
  - name: engineering
    description: "Engineering and technical problem-solving"
    mmlu_categories: ["engineering"]

# Decisions define routing logic with domain-based conditions
strategy: "priority"

decisions:
  - name: "business_decision"
    description: "Business and management queries"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "business"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a senior business consultant and strategic advisor with expertise in corporate strategy, operations management, financial analysis, marketing, and organizational development. Provide practical, actionable business advice backed by proven methodologies and industry best practices. Consider market dynamics, competitive landscape, and stakeholder interests in your recommendations."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "law_decision"
    description: "Legal questions and law-related topics"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "law"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a knowledgeable legal expert with comprehensive understanding of legal principles, case law, statutory interpretation, and legal procedures across multiple jurisdictions. Provide accurate legal information and analysis while clearly stating that your responses are for informational purposes only and do not constitute legal advice. Always recommend consulting with qualified legal professionals for specific legal matters."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "psychology_decision"
    description: "Psychology and mental health topics"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "psychology"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a psychology expert with deep knowledge of cognitive processes, behavioral patterns, mental health, developmental psychology, social psychology, and therapeutic approaches. Provide evidence-based insights grounded in psychological research and theory. When discussing mental health topics, emphasize the importance of professional consultation and avoid providing diagnostic or therapeutic advice."
      - type: "semantic-cache"
        configuration:
          enabled: true
          similarity_threshold: 0.92
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "biology_decision"
    description: "Biology and life sciences questions"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "biology"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a biology expert with comprehensive knowledge spanning molecular biology, genetics, cell biology, ecology, evolution, anatomy, physiology, and biotechnology. Explain biological concepts with scientific accuracy, use appropriate terminology, and provide examples from current research. Connect biological principles to real-world applications and emphasize the interconnectedness of biological systems."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "chemistry_decision"
    description: "Chemistry and chemical sciences questions"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "chemistry"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: true
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a chemistry expert specializing in chemical reactions, molecular structures, and laboratory techniques. Provide detailed, step-by-step explanations."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "history_decision"
    description: "Historical questions and cultural topics"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "history"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a historian with expertise across different time periods and cultures. Provide accurate historical context and analysis."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "health_decision"
    description: "Health and medical information queries"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "health"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a health and medical information expert with knowledge of anatomy, physiology, diseases, treatments, preventive care, nutrition, and wellness. Provide accurate, evidence-based health information while emphasizing that your responses are for educational purposes only and should never replace professional medical advice, diagnosis, or treatment. Always encourage users to consult healthcare professionals for medical concerns and emergencies."
      - type: "semantic-cache"
        configuration:
          enabled: true
          similarity_threshold: 0.95
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "economics_decision"
    description: "Economics and financial topics"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "economics"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are an economics expert with deep understanding of microeconomics, macroeconomics, econometrics, financial markets, monetary policy, fiscal policy, international trade, and economic theory. Analyze economic phenomena using established economic principles, provide data-driven insights, and explain complex economic concepts in accessible terms. Consider both theoretical frameworks and real-world applications in your responses."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "math_decision"
    description: "Mathematics and quantitative reasoning"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "math"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: true
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a mathematics expert. Provide step-by-step solutions, show your work clearly, and explain mathematical concepts in an understandable way."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "physics_decision"
    description: "Physics and physical sciences"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "physics"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: true
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a physics expert with deep understanding of physical laws and phenomena. Provide clear explanations with mathematical derivations when appropriate."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "computer_science_decision"
    description: "Computer science and programming"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "computer_science"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a computer science expert with knowledge of algorithms, data structures, programming languages, and software engineering. Provide clear, practical solutions with code examples when helpful."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "philosophy_decision"
    description: "Philosophy and ethical questions"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "philosophy"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a philosophy expert with comprehensive knowledge of philosophical traditions, ethical theories, logic, metaphysics, epistemology, political philosophy, and the history of philosophical thought. Engage with complex philosophical questions by presenting multiple perspectives, analyzing arguments rigorously, and encouraging critical thinking. Draw connections between philosophical concepts and contemporary issues while maintaining intellectual honesty about the complexity and ongoing nature of philosophical debates."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "engineering_decision"
    description: "Engineering and technical problem-solving"
    priority: 100
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "engineering"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are an engineering expert with knowledge across multiple engineering disciplines including mechanical, electrical, civil, chemical, software, and systems engineering. Apply engineering principles, design methodologies, and problem-solving approaches to provide practical solutions. Consider safety, efficiency, sustainability, and cost-effectiveness in your recommendations. Use technical precision while explaining concepts clearly, and emphasize the importance of proper engineering practices and standards."
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []

  - name: "general_decision"
    description: "General knowledge and miscellaneous topics"
    priority: 50
    rules:
      operator: "AND"
      conditions:
        - type: "domain"
          name: "other"
    modelRefs:
      - model: "qwen2.5:3b"
        use_reasoning: false
    plugins:
      - type: "system_prompt"
        configuration:
          system_prompt: "You are a helpful and knowledgeable assistant. Provide accurate, helpful responses across a wide range of topics."
      - type: "semantic-cache"
        configuration:
          enabled: true
          similarity_threshold: 0.75
      - type: "pii"
        configuration:
          enabled: true
          pii_types_allowed: []


default_model: "qwen2.5:3b"

# Reasoning family configurations
reasoning_families:
  deepseek:
    type: "chat_template_kwargs"
    parameter: "thinking"

  qwen3:
    type: "chat_template_kwargs"
    parameter: "enable_thinking"

  gpt-oss:
    type: "reasoning_effort"
    parameter: "reasoning_effort"
  gpt:
    type: "reasoning_effort"
    parameter: "reasoning_effort"

# Global default reasoning effort level
default_reasoning_effort: low

# API Configuration
api:
  batch_classification:
    max_batch_size: 100
    concurrency_threshold: 5
    max_concurrency: 8
    metrics:
      enabled: true
      detailed_goroutine_tracking: true
      high_resolution_timing: false
      sample_rate: 1.0
      duration_buckets:
        [0.001, 0.005, 0.01, 0.025, 0.05, 0.1, 0.25, 0.5, 1, 2.5, 5, 10, 30]
      size_buckets: [1, 2, 5, 10, 20, 50, 100, 200]

# Embedding Models Configuration
# These models provide intelligent embedding generation with automatic routing:
# - Qwen3-Embedding-0.6B: Up to 32K context, high quality,
# - EmbeddingGemma-300M: Up to 8K context, fast inference, Matryoshka support (768/512/256/128)
embedding_models:
  qwen3_model_path: "models/mom-embedding-pro"
  # gemma_model_path: "models/mom-embedding-flash"
  use_cpu: true  # Set to false for GPU acceleration (requires CUDA)
  # HNSW Configuration
  # Improves performance by preloading candidate embeddings at startup
  # and using HNSW index for O(log n) similarity search
  hnsw_config:
    model_type: "qwen3"         # Which model to use: "qwen3" (high quality) or "gemma" (fast)
    preload_embeddings: true    # Precompute candidate embeddings at startup
    target_dimension: 1024       # Embedding dimension
    enable_soft_matching: true
    min_score_threshold: 0.5

# Observability Configuration
observability:
  metrics:
    enabled: true  # Set to false to disable the Prometheus /metrics endpoint
  tracing:
    enabled: true  # Enable distributed tracing for docker-compose stack
    provider: "opentelemetry"  # Provider: opentelemetry, openinference, openllmetry
    exporter:
      type: "otlp"  # Export spans to Jaeger (via OTLP gRPC)
      endpoint: "jaeger:4317"  # Jaeger collector inside compose network
      insecure: true  # Use insecure connection (no TLS)
    sampling:
      type: "always_on"  # Sampling: always_on, always_off, probabilistic
      rate: 1.0  # Sampling rate for probabilistic (0.0-1.0)
    resource:
      service_name: "vllm-semantic-router"
      service_version: "v0.1.0"
      deployment_environment: "development"
