---
translation:
  source_commit: "bac2743"
  source_file: "docs/tutorials/intelligent-route/router-memory.md"
  outdated: false
---

# å¤šè½®å¯¹è¯ (Multi Turn Conversations)

è·¯ç”±è®°å¿† (Router Memory) é€šè¿‡ [OpenAI Response API](https://platform.openai.com/docs/api-reference/responses) å®ç°æœ‰çŠ¶æ€å¯¹è¯ï¼Œæ”¯æŒä½¿ç”¨ `previous_response_id` è¿›è¡Œå¯¹è¯é“¾å¼è°ƒç”¨ã€‚

## æ¦‚è§ˆ

Semantic Router å……å½“ä»…æ”¯æŒ Chat Completions API çš„å¤šä¸ª LLM åç«¯çš„**ç»Ÿä¸€å¤§è„‘**ã€‚å®ƒæä¾›ï¼š

- **è·¨æ¨¡å‹æœ‰çŠ¶æ€å¯¹è¯**ï¼šè·¨ä¸åŒæ¨¡å‹ç»´æŠ¤å¯¹è¯å†å²
- **ç»Ÿä¸€çš„ Response API**ï¼šæ— è®ºåç«¯æ¨¡å‹å¦‚ä½•ï¼Œå‡ä½¿ç”¨å•ä¸€çš„ API æ¥å£
- **é€æ˜è½¬æ¢**ï¼šResponse API ä¸ Chat Completions ä¹‹é—´çš„è‡ªåŠ¨è½¬æ¢

```mermaid
flowchart TB
    subgraph Clients["å®¢æˆ·ç«¯"]
        C1[Agent A]
        C2[Agent B]
    end

    subgraph SR["Semantic Router "]
        API[Response API]
        Store[(å¯¹è¯å­˜å‚¨)]
    end

    subgraph Backends["LLM åç«¯ (ä»… Chat Completions)"]
        M1[GPT-4o]
        M2[Claude]
        M3[Qwen]
        M4[Llama]
    end

    C1 & C2 --> API
    API <--> Store
    API --> M1 & M2 & M3 & M4
```

é€šè¿‡è·¯ç”±è®°å¿†ï¼Œæ‚¨å¯ä»¥ä»ä¸€ä¸ªæ¨¡å‹å¼€å§‹å¯¹è¯å¹¶ä½¿ç”¨å¦ä¸€ä¸ªæ¨¡å‹ç»§ç»­å¯¹è¯â€”â€”å¯¹è¯å†å²ä¿å­˜åœ¨è·¯ç”±ä¸­ï¼Œè€Œä¸æ˜¯ä¿å­˜åœ¨ä»»ä½•å•ä¸ªåç«¯ä¸­ã€‚

## è¯·æ±‚æµç¨‹

```mermaid
flowchart TB
    subgraph Client["å®¢æˆ·ç«¯"]
        A1[POST /v1/responses]
    end

    subgraph Router["Semantic Router  (extproc)"]
        B1[æ¥æ”¶è¯·æ±‚]
        B2{æ˜¯å¦æœ‰ previous_response_id?}
        B3[åŠ è½½å¯¹è¯é“¾]
        B4[è½¬æ¢ä¸º Chat Completions]
        B5[è½¬æ¢ä¸º Response API]
        B6[å­˜å‚¨å“åº”]
    end

    subgraph Store["å“åº”å­˜å‚¨"]
        C1[(å†…å­˜)]
    end

    subgraph Backend["åç«¯ LLM"]
        D1[POST /v1/chat/completions]
    end

    A1 --> B1
    B1 --> B2
    B2 -->|æ˜¯| B3
    B2 -->|å¦| B4
    B3 --> C1
    C1 --> B4
    B4 --> D1
    D1 --> B5
    B5 --> B6
    B6 --> C1
    B6 --> A1
```

## ç«¯ç‚¹ (Endpoints)

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° |
|----------|--------|-------------|
| `/v1/responses` | POST | åˆ›å»ºæ–°å“åº” |
| `/v1/responses/{id}` | GET | è·å–å·²å­˜å‚¨çš„å“åº” |
| `/v1/responses/{id}` | DELETE | åˆ é™¤å·²å­˜å‚¨çš„å“åº” |
| `/v1/responses/{id}/input_items` | GET | åˆ—å‡ºå“åº”çš„è¾“å…¥é¡¹ |

## é…ç½®

```yaml
response_api:
  enabled: true
  store_backend: "memory"   # ç›®å‰ä»…æ”¯æŒ "memory"
  ttl_seconds: 86400        # é»˜è®¤ï¼š30 å¤©
  max_responses: 1000
```

## ç”¨æ³•

### 1. åˆ›å»ºå“åº”

```bash
curl -X POST http://localhost:8801/v1/responses \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/gpt-oss-120b",
    "input": "è®²ä¸ªç¬‘è¯ã€‚",
    "instructions": "è®°ä½æˆ‘çš„åå­—æ˜¯ Xunzhuoã€‚ç¨åæˆ‘ä¼šé—®ä½ ï¼",
    "temperature": 0.7,
    "max_output_tokens": 100
  }'
```

å“åº”ï¼š

```json
{
  "id": "resp_7cb437001e1ad5b84b6dd8ef",
  "object": "response",
  "status": "completed",
  "output": [
    {
      "type": "message",
      "role": "assistant",
      "content": [{"type": "output_text", "text": "æ²¡é—®é¢˜ï¼ŒXunzhuoï¼ä¸ºä»€ä¹ˆç§‘å­¦å®¶ä¸ç›¸ä¿¡åŸå­ï¼Ÿå› ä¸ºå®ƒä»¬æ„æˆäº†ä¸‡ç‰©ï¼ğŸ˜„"}]
    }
  ],
  "usage": {"input_tokens": 94, "output_tokens": 75, "total_tokens": 169}
}
```

### 2. ç»§ç»­å¯¹è¯

ä½¿ç”¨ `previous_response_id` é“¾å¼è°ƒç”¨å¯¹è¯ï¼š

```bash
curl -X POST http://localhost:8801/v1/responses \
  -H "Content-Type: application/json" \
  -d '{
    "model": "openai/gpt-oss-120b",
    "input": "æˆ‘çš„åå­—æ˜¯ä»€ä¹ˆï¼Ÿ",
    "previous_response_id": "resp_7cb437001e1ad5b84b6dd8ef",
    "max_output_tokens": 100
  }'
```

å“åº”ï¼š

```json
{
  "id": "resp_ec2822df62e390dcb87aa61d",
  "status": "completed",
  "output": [
    {
      "type": "message",
      "role": "assistant",
      "content": [{"type": "output_text", "text": "ä½ çš„åå­—æ˜¯ Xunzhuoã€‚"}]
    }
  ],
  "previous_response_id": "resp_7cb437001e1ad5b84b6dd8ef"
}
```

### 3. è·å–å“åº”

```bash
curl http://localhost:8801/v1/responses/resp_7cb437001e1ad5b84b6dd8ef
```

### 4. åˆ—å‡ºè¾“å…¥é¡¹

```bash
curl http://localhost:8801/v1/responses/resp_7cb437001e1ad5b84b6dd8ef/input_items
```

å“åº”ï¼š

```json
{
  "object": "list",
  "data": [
    {
      "type": "message",
      "role": "system",
      "content": [{"type": "input_text", "text": "è®°ä½æˆ‘çš„åå­—æ˜¯ Xunzhuoã€‚"}]
    }
  ],
  "has_more": false
}
```

### 5. åˆ é™¤å“åº”

```bash
curl -X DELETE http://localhost:8801/v1/responses/resp_7cb437001e1ad5b84b6dd8ef
```

## API æ˜ å°„

| Response API | Chat Completions |
|--------------|------------------|
| `input` | `messages[].content` (role: user) |
| `instructions` | `messages[0]` (role: system) |
| `previous_response_id` | å±•å¼€ä¸ºå®Œæ•´çš„ `messages` æ•°ç»„ |
| `max_output_tokens` | `max_tokens` |

## å‚è€ƒ

- [OpenAI Response API](https://platform.openai.com/docs/api-reference/responses)
